import streamlit as st
import pandas as pd

# ---------------------------- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ----------------------------

def read_uploaded_file(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ã‚·ãƒ¼ãƒˆåã‚’ã‚­ãƒ¼ã€DataFrameã‚’å€¤ã¨ã™ã‚‹è¾æ›¸ã‚’è¿”ã—ã¾ã™ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«ãŒNoneã®å ´åˆã¯ç©ºã®è¾æ›¸ã‚’è¿”ã—ã¾ã™ã€‚
    """
    if uploaded_file is not None:
        return pd.read_excel(uploaded_file, sheet_name=None, header=None)
    return {}

def extract_mapping(helper_sheets):
    """
    è£œåŠ©ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆã‹ã‚‰ã€é™¤å¤–ã‚³ãƒ¼ãƒ‰ã€å£²ä¸Šä¿®æ­£ãƒãƒƒãƒ—ã€ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ—ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    """
    exclude_codes = []
    if "å‰Šé™¤ä¾é ¼" in helper_sheets:
        # å‰Šé™¤ä¾é ¼ã‚·ãƒ¼ãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã€æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‚¼ãƒ­åŸ‹ã‚
        codes = helper_sheets["å‰Šé™¤ä¾é ¼"].iloc[:, 0].dropna()
        codes = codes.astype(str).str.replace(r"\.0$", "", regex=True).str.zfill(4)
        exclude_codes = codes.tolist()

    fix_sales_map = {}
    if "è¨ˆç®—ä¿®æ­£" in helper_sheets:
        # è¨ˆç®—ä¿®æ­£ã‚·ãƒ¼ãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã¨ä¿®æ­£ä¿‚æ•°ã‚’æŠ½å‡ºã—ã€ãƒãƒƒãƒ—ã‚’ä½œæˆ
        sheet = helper_sheets["è¨ˆç®—ä¿®æ­£"].iloc[:, :2].dropna(how="all")
        for _, row in sheet.iterrows():
            try:
                code = str(int(row[0])).zfill(4)
                factor = float(row[1])
                fix_sales_map[code] = factor
            except ValueError: # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒ
                st.warning(f"ã€Œè¨ˆç®—ä¿®æ­£ã€ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒä¸æ­£ã§ã™: {row.tolist()}")
                continue

    category_map = {}
    if "å¤§åˆ†é¡ã‚ã‘" in helper_sheets:
        # å¤§åˆ†é¡ã‚ã‘ã‚·ãƒ¼ãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã¨ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºã—ã€ãƒãƒƒãƒ—ã‚’ä½œæˆ
        sheet = helper_sheets["å¤§åˆ†é¡ã‚ã‘"].iloc[:, :2].dropna(how="all")
        for _, row in sheet.iterrows():
            try:
                code = str(int(row[0])).zfill(4)
                category = str(row[1]).strip()
                category_map[code] = category
            except ValueError: # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒ
                st.warning(f"ã€Œå¤§åˆ†é¡ã‚ã‘ã€ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒä¸æ­£ã§ã™: {row.tolist()}")
                continue

    return exclude_codes, fix_sales_map, category_map

def clean_sheet(df, exclude_codes, fix_sales_map, category_map):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å¿…è¦ãªåˆ—ã‚’æ•´å½¢ã—ã¾ã™ã€‚
    """
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ç‰¹å®šï¼ˆ"å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"ã‚’å«ã‚€è¡Œï¼‰
    header_idx = df[df.apply(lambda r: r.astype(str).str.contains("å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", na=False)).any(axis=1)].index
    if len(header_idx) == 0:
        return pd.DataFrame() # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
    header = header_idx[0]

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šã—ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚ˆã‚Šå‰ã®è¡Œã‚’å‰Šé™¤
    df.columns = df.iloc[header]
    df = df[(header + 1):].reset_index(drop=True)

    # å¿…é ˆåˆ—ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    required_columns = {"å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆå", "ç´”å£²ä¸Šé¡"}
    if not required_columns.issubset(df.columns):
        return pd.DataFrame() # å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™

    # å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰ã®æ•´å½¢ï¼ˆæ–‡å­—åˆ—åŒ–ã€å°æ•°ç‚¹é™¤å»ã€ã‚¼ãƒ­åŸ‹ã‚ï¼‰
    df["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"] = df["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"].astype(str).str.replace(r"\.0$", "", regex=True).str.zfill(4)
    # é™¤å¤–ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    df = df[~df["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"].isin(exclude_codes)]

    # ç´”å£²ä¸Šé¡ã®ä¿®æ­£ï¼ˆè¨ˆç®—ä¿®æ­£ãƒãƒƒãƒ—ã‚’é©ç”¨ï¼‰
    df["ç´”å£²ä¸Šé¡"] = df.apply(
        lambda r: r["ç´”å£²ä¸Šé¡"] * fix_sales_map.get(r["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"], 1.0),
        axis=1
    )
    # å¤§åˆ†é¡ã®å‰²ã‚Šå½“ã¦ï¼ˆã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ—ã‚’é©ç”¨ã€æœªåˆ†é¡ã¯"æœªåˆ†é¡"ï¼‰
    df["å¤§åˆ†é¡"] = df["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"].map(category_map).fillna("æœªåˆ†é¡")

    # ç·å£²ä¸Šé¡ã‚’è¨ˆç®—ã—ã€æ§‹æˆæ¯”ã‚’ç®—å‡º
    total_sales = df["ç´”å£²ä¸Šé¡"].sum()
    df["æ§‹æˆæ¯”"] = (df["ç´”å£²ä¸Šé¡"] / total_sales * 100).round(2) if total_sales != 0 else 0.0

    # å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰ã€å¾—æ„å…ˆåã€å¤§åˆ†é¡ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å£²ä¸Šé¡ã¨æ§‹æˆæ¯”ã‚’é›†è¨ˆ
    grouped = (
        df.groupby(["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆå", "å¤§åˆ†é¡"], as_index=False)
        .agg({"ç´”å£²ä¸Šé¡": "sum", "æ§‹æˆæ¯”": "sum"})
        .sort_values("ç´”å£²ä¸Šé¡", ascending=False)
    )

    return grouped

def compare_years(prev_df, curr_df):
    """
    å‰å¹´ãƒ‡ãƒ¼ã‚¿ã¨ä»Šå¹´ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒã—ã€å·®é¡ã¨å‰å¹´æ¯”ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    """
    merged = pd.merge(
        prev_df,
        curr_df,
        on=["å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆå", "å¤§åˆ†é¡"],
        how="outer", # ã©ã¡ã‚‰ã‹ã®å¹´ã«ã—ã‹å­˜åœ¨ã—ãªã„å¾—æ„å…ˆã‚‚å«ã‚€
        suffixes=("_å‰å¹´", "_ä»Šå¹´"),
    )

    # æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
    for col in ["ç´”å£²ä¸Šé¡_å‰å¹´", "ç´”å£²ä¸Šé¡_ä»Šå¹´", "æ§‹æˆæ¯”_å‰å¹´", "æ§‹æˆæ¯”_ä»Šå¹´"]:
        merged[col] = merged[col].fillna(0)

    # å£²ä¸Šé¡ã‚’åƒå††å˜ä½ã«ä¸¸ã‚ã‚‹
    merged["ç´”å£²ä¸Šé¡_å‰å¹´"] = (merged["ç´”å£²ä¸Šé¡_å‰å¹´"] / 1000).round().astype("Int64")
    merged["ç´”å£²ä¸Šé¡_ä»Šå¹´"] = (merged["ç´”å£²ä¸Šé¡_ä»Šå¹´"] / 1000).round().astype("Int64")

    # å·®é¡ã¨å‰å¹´æ¯”ã‚’è¨ˆç®—
    merged["å·®é¡"] = merged["ç´”å£²ä¸Šé¡_ä»Šå¹´"] - merged["ç´”å£²ä¸Šé¡_å‰å¹´"]
    merged["å‰å¹´æ¯”(%)"] = merged.apply(
        lambda row: round(row["ç´”å£²ä¸Šé¡_ä»Šå¹´"] / row["ç´”å£²ä¸Šé¡_å‰å¹´"] * 100, 1)
        if row["ç´”å£²ä¸Šé¡_å‰å¹´"] != 0 else (100.0 if row["ç´”å£²ä¸Šé¡_ä»Šå¹´"] != 0 else 0.0), # å‰å¹´ãŒ0ã®å ´åˆã¯ä»Šå¹´ãŒ0ã§ãªã‘ã‚Œã°100%
        axis=1
    )

    # è¡¨ç¤ºåˆ—ã®é †åºã‚’å®šç¾©
    ordered_cols = [
        "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆå", "å¤§åˆ†é¡",
        "ç´”å£²ä¸Šé¡_ä»Šå¹´", "æ§‹æˆæ¯”_ä»Šå¹´",
        "ç´”å£²ä¸Šé¡_å‰å¹´", "æ§‹æˆæ¯”_å‰å¹´",
        "å‰å¹´æ¯”(%)", "å·®é¡"
    ]
    return merged[ordered_cols]

def summarize_by_category(comp_df):
    """
    ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆã—ã¾ã™ã€‚
    """
    cat = comp_df.groupby("å¤§åˆ†é¡", as_index=False).agg({
        "ç´”å£²ä¸Šé¡_å‰å¹´": "sum",
        "ç´”å£²ä¸Šé¡_ä»Šå¹´": "sum",
        "å·®é¡": "sum"
    })
    cat["å‰å¹´æ¯”(%)"] = cat.apply(
        lambda r: round(r["ç´”å£²ä¸Šé¡_ä»Šå¹´"] / r["ç´”å£²ä¸Šé¡_å‰å¹´"] * 100, 1)
        if r["ç´”å£²ä¸Šé¡_å‰å¹´"] != 0 else (100.0 if r["ç´”å£²ä¸Šé¡_ä»Šå¹´"] != 0 else 0.0),
        axis=1
    )
    return cat

# ---------------------------- Streamlit ã‚¢ãƒ—ãƒª ----------------------------

st.set_page_config(page_title="å¸å–¶æ¥­æ•°å€¤åˆ†æã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“Š å¸å–¶æ¥­æ•°å€¤åˆ†æã‚·ã‚¹ãƒ†ãƒ ")

st.markdown("### Step 0: ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
prev_file = st.file_uploader("å‰å¹´ãƒ‡ãƒ¼ã‚¿ (Excel)", type=["xlsx"], key="prev_file_uploader")
curr_file = st.file_uploader("ä»Šå¹´ãƒ‡ãƒ¼ã‚¿ (Excel)", type=["xlsx"], key="curr_file_uploader")
helper_file = st.file_uploader("è£œåŠ©ãƒ‡ãƒ¼ã‚¿ (ãƒ‡ãƒ¼ã‚¿æ•´ç†.xlsx)", type=["xlsx"], key="helper_file_uploader")

if prev_file and curr_file and helper_file:
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    prev_sheets = read_uploaded_file(prev_file)
    curr_sheets = read_uploaded_file(curr_file)
    helper_sheets = read_uploaded_file(helper_file)

    # è£œåŠ©ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°æŠ½å‡º
    exclude_codes, fix_sales_map, category_map = extract_mapping(helper_sheets)

    # å„Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
    # ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ 
    if not prev_sheets:
        st.error("å‰å¹´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    prev_sheet_df = list(prev_sheets.values())[0]

    if not curr_sheets:
        st.error("ä»Šå¹´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    curr_sheet_df = list(curr_sheets.values())[0]

    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    prev_clean = clean_sheet(prev_sheet_df, exclude_codes, fix_sales_map, category_map)
    curr_clean = clean_sheet(curr_sheet_df, exclude_codes, fix_sales_map, category_map)

    if prev_clean.empty or curr_clean.empty:
        st.error("ãƒ˜ãƒƒãƒ€è¡Œï¼ˆå¾—æ„å…ˆã‚³ãƒ¼ãƒ‰ãªã©ï¼‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€ã¾ãŸã¯å¿…é ˆåˆ—ï¼ˆå¾—æ„å…ˆã‚³ãƒ¼ãƒ‰ã€å¾—æ„å…ˆåã€ç´”å£²ä¸Šé¡ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Excelã®åˆ—æ§‹æˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.stop()

    st.markdown("### Step 1: æ•´ç†å¾Œãƒ‡ãƒ¼ã‚¿")
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("å‰å¹´æ•´ç†ãƒ‡ãƒ¼ã‚¿")
        st.dataframe(prev_clean, use_container_width=True)
    with col2:
        st.subheader("ä»Šå¹´æ•´ç†ãƒ‡ãƒ¼ã‚¿")
        st.dataframe(curr_clean, use_container_width=True)

    st.markdown("### Step 2: å‰å¹´ vs ä»Šå¹´ æ¯”è¼ƒï¼ˆåƒå††å˜ä½ï¼‰")
    comp_df = compare_years(prev_clean, curr_clean)
    st.dataframe(comp_df, use_container_width=True)

    st.markdown("### Step 3: ä¸¦ã³æ›¿ãˆã¨é›†è¨ˆ")
    option = st.selectbox(
        "ä¸¦ã³æ›¿ãˆåŸºæº–ã‚’é¸ã‚“ã§ãã ã•ã„",
        (
            "å¤§åˆ†é¡åˆ¥ï¼ˆç´”å£²ä¸Šé¡ï¼¿ä»Šå¹´é †ï¼‰",
            "å¤§åˆ†é¡åˆ¥ï¼ˆå·®é¡ãƒ™ã‚¹ãƒˆé †ï¼‰",
            "å¤§åˆ†é¡åˆ¥ï¼ˆå·®é¡ãƒ¯ãƒ¼ã‚¹ãƒˆé †ï¼‰",
            "å¾—æ„å…ˆåˆ¥ï¼ˆç´”å£²ä¸Šé¡ï¼¿ä»Šå¹´é †ï¼‰",
            "å¾—æ„å…ˆåˆ¥ï¼ˆå·®é¡ãƒ™ã‚¹ãƒˆé †ï¼‰",
            "å¾—æ„å…ˆåˆ¥ï¼ˆå·®é¡ãƒ¯ãƒ¼ã‚¹ãƒˆé †ï¼‰",
        ),
        key="sort_option_select" # ã‚­ãƒ¼ã‚’è¿½åŠ 
    )

    if option.startswith("å¤§åˆ†é¡åˆ¥"):
        summary_df = summarize_by_category(comp_df)
        if "ç´”å£²ä¸Šé¡é †" in option:
            summary_sorted = summary_df.sort_values("ç´”å£²ä¸Šé¡_ä»Šå¹´", ascending=False)
        elif "ãƒ™ã‚¹ãƒˆ" in option:
            summary_sorted = summary_df.sort_values("å·®é¡", ascending=False)
        else: # ãƒ¯ãƒ¼ã‚¹ãƒˆé †
            summary_sorted = summary_df.sort_values("å·®é¡")
        st.dataframe(summary_sorted, use_container_width=True)
        # æ£’ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
        if not summary_sorted.empty:
            st.bar_chart(summary_sorted.set_index("å¤§åˆ†é¡")["ç´”å£²ä¸Šé¡_ä»Šå¹´"])
        else:
            st.info("é›†è¨ˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else: # å¾—æ„å…ˆåˆ¥
        if "ç´”å£²ä¸Šé¡é †" in option:
            df_sorted = comp_df.sort_values("ç´”å£²ä¸Šé¡_ä»Šå¹´", ascending=False)
        elif "ãƒ™ã‚¹ãƒˆ" in option:
            df_sorted = comp_df.sort_values("å·®é¡", ascending=False)
        else: # ãƒ¯ãƒ¼ã‚¹ãƒˆé †
            df_sorted = comp_df.sort_values("å·®é¡")
        st.markdown("### å¾—æ„å…ˆåˆ¥ï¼šæ¯”è¼ƒçµæœ")
        if not df_sorted.empty:
            st.dataframe(df_sorted, use_container_width=True)
        else:
            st.info("é›†è¨ˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.success("åˆ†æå®Œäº†ï¼")
else:
    st.info("å‰å¹´ãƒ»ä»Šå¹´ãƒ»è£œåŠ©ãƒ‡ãƒ¼ã‚¿ã®3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# ãƒ›ãƒ¼ãƒ ç”»é¢ã«æˆ»ã‚‹ãƒªãƒ³ã‚¯ã‚’ä¸€ç•ªä¸‹ã«è¿½åŠ 
st.markdown("---")
st.page_link("åˆ†æãƒ„ãƒ¼ãƒ«ã¾ã¨ã‚.py", label="ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«æˆ»ã‚‹ğŸ  ", icon="ğŸ ")